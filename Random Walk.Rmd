---
title: "Random Walk"
output: html_document
date: "2024-11-18"
---

```{r}
library(knitr)

```


## Definição do processo estocástico (cadeia de Markov);

Suponha que $U=(U_{1},U_{2},U_{3}...)$ é uma sequência de variáveis aleatória independetes, com valores entre 1 e -1 e probabilidades $p \in[0,1]$ e $1-p$ respectivamente. Seja $X= (X_{0},X_{1},X_{2}...)$ a soma parcial do processo associado a $U$, então:

$$X_{n}=\sum_{i=1}^{n}U_{i}$$

A sequência $X$ é chamada de passeio aleatório simples (ou somente passeio aleatório) com parametro $p$.

Agora suponha que $p=\frac{1}{2}$. Nesse caso, $X=(X_{0},X_{1},X_{2}...)$ é chamado de passeio aleatório simétrico simples (ou passeio simétrico aleatório). Em particular,

$$P(X_{i}=e_{i})=P(X_{i}=-e_{i})=\frac{1}{2d}, i=1,2,3...d.$$

Ou seja, em um passeio aleatório simétrico, o usuário se desloca aleatoriamente um passo por vez, com todas as direções possíveis sendo igualmente prováveis. Por exemplo, em duas dimensões ($d=2$), ele pode ir para cima, baixo, esquerda ou direita, com probabilidade de $\frac{1}{4}$ para cada direção.

#### Esperança

Como $X_{n}$ é a soma de variáveis aleatórias $U_{i}$, a esperança de $X_{n}$ pode ser obtida:
$$
\mathbb{E}[X_{n}]=\mathbb{E}[\sum_{i=1}^{n}U_{i}]=\sum_{i=1}^{n}\mathbb{E}[U_{i}]
$$
Como $U_{i}$ assume +1 e -1 ambos com probabilidade $\frac{1}{2}$, temos:
$$
\mathbb{E}[U_{i}]=1\times\frac{1}{2}+(-1)\times\frac{1}{2}=0
$$
Portanto a esperança de $X_{n}$ é igual a zero.

Isso significa que, em média, o processo não tende para um lado específico, mas está igualmente "distribuído" ao redor da origem.

Fontes:

https://stats.libretexts.org/Bookshelves/Probability_Theory/Probability_Mathematical_Statistics_and_Stochastic_Processes_(Siegrist)/11%3A_Bernoulli_Trials/11.06%3A_The_Simple_Random_Walk

https://math.uchicago.edu/~may/VIGRE/VIGRE2011/REUPapers/Johnston.pdf


## Matriz de transição; 

#### Definição de Matriz de Transição

A **matriz de transição** $P$ descreve as probabilidades de transição de um estado $i$ para outro estado $j$ em um único passo.

Para o passeio aleatório com espaço de estados $S= \mathbb{Z}$, temos:

$$ 
P_{i,j} = 
\begin{cases} 
p & \text{se } j = i+1, \\
1-p & \text{se } j = i-1, \\
0 & \text{caso contrário.}
\end{cases}
$$

#### Representação da Matriz $P$

Se $S = \{0, 1, 2 ,3 ,4\}$ um espaço de estados discreto finito, a matriz de transição $P$ é dada por:

$$
P = 
\begin{bmatrix}
P_{0,0} & P_{0,1} & P_{0,2} & P_{0,3} & P_{0,4} \\
P_{1,0} & P_{1,1} & P_{1,2} & P_{1,3} & P_{1,4} \\
P_{2,0} & P_{2,1} & P_{2,2} & P_{2,3} & P_{2,4} \\
P_{3,0} & P_{3,1} & P_{3,2} & P_{3,3} & P_{3,4} \\
P_{4,0} & P_{4,1} & P_{4,2} & P_{4,3} & P_{4,4} 
\end{bmatrix}. 
$$

Para o nosso caso de passeio aleatório **finito** $S =\{0,1,2,...,N\}$ a matriz de transição será uma matriz $(N+1)\times(N+1)$.

Mas também nesse caso precisamos definir umas condições de contorno:
- **Contorno reflexivo**: Se estamos no estado extremo $i=0$ ou $i=N$, o sistema "rebate" e não sai do espaço
- **Contorno absorvente**: O sistema permanece no estado extremo $i=0$ ou $i=N$

Vamos definir o **Contorno Reflexivo** para estudo e apresentação deste trabalho, pois note que definindo o contorno da matriz de transição sofremos alteração no problema todo como um geral e suas distribuições.

$$
P =
\begin{bmatrix}
1-p & p & 0 & \dots & 0 \\
1-p & 0 & p & \dots & 0 \\
0 & 1-p & 0 & \dots & p \\
\vdots & \vdots & \ddots & \ddots & \vdots \\
0 & \dots & 0 & 1-p & p \\
0 & \dots & 0 & 1-p & p
\end{bmatrix}.
$$

*Propriedades da Matriz de Transição*: **Estocasticidade**, **Simetria (para $p=1/2$)**, **Sparsa** (para eu estudar para apresentação)

Como estamos trabalhando com passeio aleatório simétrico, temos $p = \frac{1}{2}$. Temos simetria pois as probabilidades de transição para frente $(i + 1)$ e para trás $(i - 1)$ são iguais!
Consequentemente, temos para assimétrico $p \neq \frac{1}{2}$.

Podemos analisar as matrizes dada a simetria e assímetria associadas e suas propriedades!

#### **4. Exemplo para \( N = 3 \) (espaço \( S = \{0, 1, 2, 3\} \))**
Com \( p = 0.5 \) e contornos reflexivos:
$$
P =
\begin{bmatrix}
0.5 & 0.5 & 0 & 0 \\
0.5 & 0 & 0.5 & 0 \\
0 & 0.5 & 0 & 0.5 \\
0 & 0 & 0.5 & 0.5
\end{bmatrix}.
$$
*Propriedades Específicas*: **Recorrência**, **Distribuição Assintótica**

#### Caso passeio Aleatório Assimétrico $p \neq \frac{1}{2}$
Com \( p = 0.66 \) e contornos reflexivos:
$$
P =
\begin{bmatrix}
0.33 & 0.66 & 0 & 0 \\
0.33 & 0 & 0.66 & 0 \\
0 & 0.33 & 0 & 0.66 \\
0 & 0 & 0.33 & 0.66
\end{bmatrix}.
$$

*Propriedades Específicas*: **Têndencia Direcional**, **Irreversibilidade**

Só para eu salvar aqui xdd
https://stats.libretexts.org/Bookshelves/Probability_Theory/Probability_Mathematical_Statistics_and_Stochastic_Processes_(Siegrist)/11%3A_Bernoulli_Trials/11.06%3A_The_Simple_Random_Walk
https://stats.libretexts.org/Bookshelves/Probability_Theory/Introductory_Probability_(Grinstead_and_Snell)/12%3A_Random_Walks

3 - distibuição invariante e distribuição limite (quando houver);

### Distribuição invariante
A **distribuição invariante** de uma cadeia de Markov como vista em aula é uma distribuição de probabilidade $\pi = (\pi_i)$ tal que, ao aplicarmos a matriz de transição $P$, a distribuição permanece inalterada tal que:
$$
\pi P = \pi.
$$

Em nosso contexto de apresentação (passeio aleatório simétrico), teriamos

- A matriz de transição $P$ é simétrica para $p = \frac{1}{2}$
- Em espaços de estados finitos, a distribuição invariante é uniforme:

$$ \pi_i = \frac{1}{|S|} $$

- para todos os estados $i$, onde $|S|$ é o número total de estados. Isso ocorre porque as transições são igualmente prováveis em todas as direções.

**Para o nosso exemplo de espaço discreto finito $S={0, 1, 2,3}:$**
$$
P = \begin{bmatrix}
\frac{1}{2} & \frac{1}{2} & 0 & 0 \\
\frac{1}{2} & 0 & \frac{1}{2} & 0 \\
0 & \frac{1}{2} & 0 & \frac{1}{2} \\
0 & 0 & \frac{1}{2} & \frac{1}{2}
\end{bmatrix} \
$$

A distribuição invariante será:

$$
\pi = \left( \frac{1}{4}, \frac{1}{4}, \frac{1}{4}, \frac{1}{4} \right)
$$

### Distribuição Limite
A **distibuição limite** de uma cadeia de Markov é o estado ao qual a distribuição converge  muitas iterações da matriz da transição, isto é, quando $n \to \infty$

$$
\lim_{n \to \infty} P^n(i, j)
$$

Como vimos em aula, um **espaço de estados finitos**, a distribuição limite será igual à distribuição invariante.

Para um **espaço infinito $S= \mathbb{Z}$** o passeio simétrico não converge para uma distribuição estacionária porque o sistema "se espalha" indefinidamente. A probabilidade de estar e um estado específico diminui com o tempo!
Ou seja, se começarmos no ponto 0, após *n* passos, a posição $X_n$ do objeto será distribuída aproximadamente como uma normal com média 0 e variância n
$$
X_n ~ N(0, n)
$$

## Classificação dos estados e da cadeia;

Por definição um estado $i$ é dito ser **recorrente** se $v_{ii}^*=1$ (a cadeira retorna ao $i$ com probabilidade 1).

O estado $i$ é dito ser transiente se ele não é recorrente.

Portanto, para a matriz de exemplo, considerando $p=\frac{1}{2}$:

$$
P = 
\begin{bmatrix}
\frac{1}{2} & \frac{1}{2} & 0 & 0 & 0 \\
\frac{1}{2} & 0 & \frac{1}{2} & 0 & 0 \\
0 & \frac{1}{2} & 0 & \frac{1}{2} & 0 \\
0 & 0 & \frac{1}{2} & 0 & \frac{1}{2} \\
0 & 0 & 0 & \frac{1}{2} & \frac{1}{2}
\end{bmatrix}.
$$

<div style="text-align: center;">
```{r, echo=FALSE, out.width="30%"}
include_graphics("img/01.png")
```
</div>

Análisando o grafo podemos notar que os estados {0,1,2,3,4} são uma classe fechada, irredutível.

George Pólya, em 1921, provou o teorema denominado "Teorema de Pólya" ou "Teorema da Recorrência de Caminhadas Aleatórias":

*"Um passeio aleatório simples em $\mathbb{Z}^D$ é recorrente se e somente se é simétrico e D < 3."*

Então, temos a distribuição estacionária: 

$$
\pi_{i}=\frac{1}{2}\pi_{i-1}+\frac{1}{2}\pi_{i}
$$
Por exemplo:

$$
\pi_{2}=\frac{1}{2}\pi_{1}+\frac{1}{2}\pi_{2}\implies \pi_{1}=\pi_{2}
$$
Podemos mostrar que:
$$
\pi_{0}=\pi_{1}=\pi_{2}=\pi_{3}=\pi_{4}
$$
Usando a condição de normalização para essa distribuição estacionária:
$$
\pi_{0}+\pi_{1}+\pi_{2}+\pi_{3}+\pi_{4}=1
$$
Portanto
$$
\pi = (\frac{1}{5},\frac{1}{5},\frac{1}{5},\frac{1}{5},\frac{1}{5})
$$
A soma das probabilidades para deslocamento a esquerda e a direita são iguais, então podemos argumentar que a distribuição estacionária é constante para todos os estados.

Assim temos, para todos os estados $i$:

$$
\pi_{i}=\pi_{0}
$$

Como temos um processo recorrente e com distribuição estacionária $\pi_{i}=\pi_{0}$ concluímos que todos os estados em um processo de caminhada aleatória simétrica de dimensão 2 são recorrentes nulos.

Ou seja, embora o processo seja recorrente, o tempo médio para retornar ao estado inicial (ou qualquer estado específico) é infinito. O processo eventualmente retorna ao estado, mas o tempo médio de retorno é infinito.

O mesmo foi provado por George Pólya: "Em dimensões $d=2$, a caminhada aleatória simétrica é recorrente, mas o tempo médio de retorno ao ponto de origem é infinito, o que caracteriza uma recorrência nula."

*Referência: Pólya, G. (1921). "Über eine Aufgabe der Wahrscheinlichkeitsrechnung betreffend die Erreichbarkeit von Punkten im Raum", Mathematische Annalen, 84, 149–160. DOI: 10.1007/BF01455746.*

## Periodicidade;
 O estado $i$ tem período d se $P_{i,i}^n = 0$ sempre que $n$ não for divisível por $d$, e $d$ é o maior inteiro com essa propriedade. Por exemplo, começando no estado $i$ só sera possível o processo acessar o estado $i$ nos tempo 2,4,6,8,..., nesse caso o estado $i$ tem período 2. Um estado com período 1 é classificado como **aperiódico**. Periodicidade é uma propriedade de classe, ou seja, se o estado $i$ tem período $d$, e o estado $i$ e $j$ se comunicam, então o estado $j$ também tem período $d$.

 *Referência: Sheldon, M. Ross: Introduction to probability models"

### Random Walk simétrica infinita com D = 1:
Como todos os estados são comunicáveis entre si, isso implica que todos os estados terão o mesmo período, de acordo com a definição de periodicidade. Podemos observar que é impossível retornar ao estado zero após um número ímpar de passos. Ou seja:

$P_{0,0}^2n-1 = 0$ 

Além disso, é possível concluir que para retornar ao estado zero, é necessário dar $n$ passos para a direita e $n$ passos para a esquerda, ou seja, somente após $2n$ passos o retorno à origem é possível. Como o retorno ao estado zero só ocorre em tempos pares, definimos o processo como tendo período $d=2$.















## Tempo de primeira visita/passagem e recorrência

## Probabilidade de absorção

## Curiosidades e questões interessantes relacionadas ao problema específico.